{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/codespace/.python/current/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'input': 'Setting up your daily to-do list...', 'instruction': 'Help me set up my daily to-do list!', 'output': \"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\"}, page_content='\"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\\\ntasks = []\\\\nwhile True:\\\\n    task = input(\\'Enter a task or type \\'done\\' to finish: \\')\\\\n    if task == \\'done\\': break\\\\n    tasks.append(task)\\\\nprint(f\\'Your to-do list for today: {tasks}\\')\\\\n```\"'),\n",
       " Document(metadata={'input': 'Creating a shopping list...', 'instruction': 'Create a shopping list based on my inputs!', 'output': \"```python\\nshopping_list = {}\\nwhile True:\\n    item = input('Enter an item or type 'done' to finish: ')\\n    if item == 'done': break\\n    quantity = input(f'Enter the quantity for {item}: ')\\n    shopping_list[item] = quantity\\nprint(f'Your shopping list: {shopping_list}')\\n```\"}, page_content='\"Create a shopping list based on my inputs! Creating a shopping list... ```python\\\\nshopping_list = {}\\\\nwhile True:\\\\n    item = input(\\'Enter an item or type \\'done\\' to finish: \\')\\\\n    if item == \\'done\\': break\\\\n    quantity = input(f\\'Enter the quantity for {item}: \\')\\\\n    shopping_list[item] = quantity\\\\nprint(f\\'Your shopping list: {shopping_list}\\')\\\\n```\"')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the dataset name and the column containing the content\n",
    "ds1 = \"flytech/python-codes-25k\"\n",
    "page_content_column = \"text\"  # or any other column you're interested in\n",
    "\n",
    "# Create a loader instance\n",
    "loader1 = HuggingFaceDatasetLoader(ds1, page_content_column)\n",
    "\n",
    "# Load the data\n",
    "data1 = loader1.load()\n",
    "\n",
    "# Display the first 2 entries\n",
    "data1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'input': 'Setting up your daily to-do list...', 'instruction': 'Help me set up my daily to-do list!', 'output': \"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\"}, page_content='\"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\\\ntasks = []\\\\nwhile True:\\\\n    task = input(\\'Enter a task or type \\'done\\' to finish: \\')\\\\n    if task == \\'done\\': break\\\\n    tasks.append(task)\\\\nprint(f\\'Your to-do list for today: {tasks}\\')\\\\n```\"'),\n",
       " Document(metadata={'input': 'Creating a shopping list...', 'instruction': 'Create a shopping list based on my inputs!', 'output': \"```python\\nshopping_list = {}\\nwhile True:\\n    item = input('Enter an item or type 'done' to finish: ')\\n    if item == 'done': break\\n    quantity = input(f'Enter the quantity for {item}: ')\\n    shopping_list[item] = quantity\\nprint(f'Your shopping list: {shopping_list}')\\n```\"}, page_content='\"Create a shopping list based on my inputs! Creating a shopping list... ```python\\\\nshopping_list = {}\\\\nwhile True:\\\\n    item = input(\\'Enter an item or type \\'done\\' to finish: \\')\\\\n    if item == \\'done\\': break\\\\n    quantity = input(f\\'Enter the quantity for {item}: \\')\\\\n    shopping_list[item] = quantity\\\\nprint(f\\'Your shopping list: {shopping_list}\\')\\\\n```\"')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the RecursiveCharacterTextSplitter class with specific parameters.\n",
    "# It splits text into chunks of 1000 characters each with a 150-character overlap.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# 'data' holds the text you want to split, split the text into documents using the text splitter.\n",
    "docs1 = text_splitter.split_documents(data1)\n",
    "\n",
    "docs1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the pre-trained model you want to use\n",
    "modelPath1 = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs1 = {'device':'cpu'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs1 = {'normalize_embeddings': False}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings1 = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath1,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs1, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs1 # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.011383002623915672, 0.042903706431388855, -0.06694354861974716]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Create a count down function.\"\n",
    "query_result1 = embeddings1.embed_query(text)\n",
    "query_result1[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(docs1, embeddings1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save VDB\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "Downloading readme: 100%|██████████| 50.0/50.0 [00:00<00:00, 351kB/s]\n",
      "Downloading data: 100%|██████████| 3.15M/3.15M [00:00<00:00, 4.71MB/s]\n",
      "Generating train split: 100%|██████████| 7609/7609 [00:00<00:00, 42630.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Number': 1}, page_content='\"A computer is a machine that can be programmed to automatically carry out sequences of arithmetic or logical operations . Modern digital electronic computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. The term computer system may refer to a nominally complete computer that includes the hardware, operating system, software, and peripheral equipment needed and used for full operation; or to a group of computers that are linked and function together, such as a computer network or computer cluster.\"'),\n",
       " Document(metadata={'Number': 2}, page_content='\"A broad range of industrial and consumer products use computers as control systems, including simple special-purpose devices like microwave ovens and remote controls, and factory devices like industrial robots. Computers are at the core of general-purpose devices such as personal computers and mobile devices such as smartphones. Computers power the Internet, which links billions of computers and users.\"'),\n",
       " Document(metadata={'Number': 3}, page_content='\"Early computers were meant to be used only for calculations. Simple manual instruments like the abacus have aided people in doing calculations since ancient times. Early in the Industrial Revolution, some mechanical devices were built to automate long, tedious tasks, such as guiding patterns for looms. More sophisticated electrical machines did specialized analog calculations in the early 20th century. The first digital electronic calculating machines were developed during World War II, both electromechanical and using thermionic valves. The first semiconductor transistors in the late 1940s were followed by the silicon-based MOSFET  and monolithic integrated circuit chip technologies in the late 1950s, leading to the microprocessor and the microcomputer revolution in the 1970s. The speed, power and versatility of computers have been increasing dramatically ever since then, with transistor counts increasing at a rapid pace , leading to the Digital Revolution during the late 20th to early 21st centuries.\"'),\n",
       " Document(metadata={'Number': 4}, page_content='\"Conventionally, a modern computer consists of at least one processing element, typically a central processing unit  in the form of a microprocessor, together with some type of computer memory, typically semiconductor memory chips. The processing element carries out arithmetic and logical operations, and a sequencing and control unit can change the order of operations in response to stored information. Peripheral devices include input devices , output devices , and input/output devices that perform both functions . Peripheral devices allow information to be retrieved from an external source and they enable the result of operations to be saved and retrieved.\"'),\n",
       " Document(metadata={'Number': 5}, page_content='\"According to the Oxford English Dictionary, the first known use of computer was in a 1613 book called The Yong Mans Gleanings by the English writer Richard Brathwait: \\\\\"I haue   read the truest computer of Times, and the best Arithmetician that euer   breathed, and he reduceth thy dayes into a short number.\\\\\" This usage of the term referred to a human computer, a person who carried out calculations or computations. The word continued with the same meaning until the middle of the 20th century. During the latter part of this period women were often hired as computers because they could be paid less than their male counterparts. By 1943, most human computers were women.\"')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify the dataset name and the column containing the content\n",
    "ds2 = \"AlaaElhilo/Wikipedia_ComputerScience\"\n",
    "page_content_column2 = \"Text\"  # or any other column you're interested in\n",
    "\n",
    "# Create a loader instance\n",
    "loader2 = HuggingFaceDatasetLoader(ds2, page_content_column2)\n",
    "\n",
    "# Load the data\n",
    "data2 = loader2.load()\n",
    "\n",
    "# Display the first 15 entries\n",
    "data2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Number': 1}, page_content='\"A computer is a machine that can be programmed to automatically carry out sequences of arithmetic or logical operations . Modern digital electronic computers can perform generic sets of operations known as programs. These programs enable computers to perform a wide range of tasks. The term computer system may refer to a nominally complete computer that includes the hardware, operating system, software, and peripheral equipment needed and used for full operation; or to a group of computers that are linked and function together, such as a computer network or computer cluster.\"'),\n",
       " Document(metadata={'Number': 2}, page_content='\"A broad range of industrial and consumer products use computers as control systems, including simple special-purpose devices like microwave ovens and remote controls, and factory devices like industrial robots. Computers are at the core of general-purpose devices such as personal computers and mobile devices such as smartphones. Computers power the Internet, which links billions of computers and users.\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the RecursiveCharacterTextSplitter class with specific parameters.\n",
    "# It splits text into chunks of 1000 characters each with a 150-character overlap.\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# 'data' holds the text you want to split, split the text into documents using the text splitter.\n",
    "docs2 = text_splitter.split_documents(data2)\n",
    "\n",
    "# Viewing first few entries\n",
    "docs2[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the pre-trained model you want to use\n",
    "modelPath2 = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "\n",
    "# Create a dictionary with model configuration options, specifying to use the CPU for computations\n",
    "model_kwargs2 = {'device':'cpu'}\n",
    "\n",
    "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
    "encode_kwargs2 = {'normalize_embeddings': False}\n",
    "\n",
    "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
    "embeddings2 = HuggingFaceEmbeddings(\n",
    "    model_name=modelPath2,     # Provide the pre-trained model's path\n",
    "    model_kwargs=model_kwargs2, # Pass the model configuration options\n",
    "    encode_kwargs=encode_kwargs2 # Pass the encoding options\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.011383002623915672, 0.042903706431388855, -0.06694354861974716]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Create a count down function.\"\n",
    "query_result2 = embeddings2.embed_query(text)\n",
    "query_result2[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "db2 = FAISS.from_documents(docs2, embeddings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save VDB\n",
    "db2.save_local(\"faiss_index1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Datasets and VDB into 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing VDBs\n",
    "embeddings = embeddings2\n",
    "vdb1 = FAISS.load_local(\"./faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "vdb2 = FAISS.load_local(\"./faiss_index1\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def merge_faiss_indexes(vdb1, vdb2):\n",
    "    # Get the IDs from both indexes\n",
    "    ids_vdb1 = set(vdb1.docstore.keys())\n",
    "    ids_vdb2 = set(vdb2.docstore.keys())\n",
    "    \n",
    "    # Find overlapping IDs\n",
    "    overlapping_ids = ids_vdb1.intersection(ids_vdb2)\n",
    "    \n",
    "    # If there are overlapping IDs, we need to handle them\n",
    "    if overlapping_ids:\n",
    "        print(f\"Found {len(overlapping_ids)} overlapping IDs. Generating new IDs for the second index...\")\n",
    "        new_docs = []\n",
    "        for doc_id, doc in vdb2.docstore.items():\n",
    "            if doc_id in overlapping_ids:\n",
    "                # Generate a new unique ID\n",
    "                new_id = str(uuid.uuid4())\n",
    "                doc['id'] = new_id\n",
    "                new_docs.append(doc)\n",
    "            else:\n",
    "                new_docs.append(doc)\n",
    "        \n",
    "        # Create a new FAISS index for the modified documents\n",
    "        vdb2_modified = FAISS.from_documents(new_docs, embeddings)\n",
    "        return vdb1.merge_from(vdb2_modified)\n",
    "    \n",
    "    return vdb1.merge_from(vdb2)\n",
    "\n",
    "# Merge FAISS indexes\n",
    "combine_vdb = merge_faiss_indexes(vdb1, vdb2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
